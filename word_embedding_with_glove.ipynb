{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_embedding_with_glove.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV64n2DxgXpC"
      },
      "source": [
        "#import glove\n",
        "!pip install glove-python\n",
        "import pandas as pd\n",
        "import re\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP_4mqhRgd1N"
      },
      "source": [
        "data = pd.read_csv(\"/content/tweet.csv\")\n",
        "Rev_tweet=data[\"tweet\"]\n",
        "Rev_tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTgRHR43gnwa"
      },
      "source": [
        "def preprocess(text):\n",
        "    clean_data = []\n",
        "    for x in (text[:]): \n",
        "\n",
        "        # remove HTML tags\n",
        "        new_text = re.sub('<.*?>', '', x)   \n",
        "\n",
        "        # remove punc.\n",
        "        new_text = re.sub(r'[^\\w\\s]', '', new_text) \n",
        "\n",
        "        # remove numbers\n",
        "        new_text = re.sub(r'\\d+','',new_text)\n",
        "\n",
        "        # lower case\n",
        "        new_text = new_text.lower() \n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  \n",
        "        u\"\\U0001F300-\\U0001F5FF\" \n",
        "        u\"\\U0001F680-\\U0001F6FF\"  \n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "        new_text = emoji_pattern.sub(r'', new_text)         \n",
        "        if new_text != '':\n",
        "            clean_data.append(new_text)\n",
        "    return clean_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VumiUvlGgt86"
      },
      "source": [
        "data['clean_text']=preprocess(Rev_tweet)\n",
        "data['clean_text']\n",
        "\n",
        "data['clean_tweets'] = data['clean_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "data['clean_tweets'] = data['clean_tweets'].fillna('').apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
        "data['clean_tweets'] = data['clean_tweets'].fillna('').apply(lambda x: x.lower())\n",
        "corpus=data['clean_tweets']\n",
        "data['clean_tweets']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1lDaI9Ug57M"
      },
      "source": [
        "# we need to pass splitted sentences to the model\n",
        "tokenized_sentences = [sentence.split() for sentence in corpus]\n",
        "lines=tokenized_sentences\n",
        "lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxW2j7zyg9-j"
      },
      "source": [
        "#importing the glove library\n",
        "from glove import Corpus, Glove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjA7nBhehBgJ"
      },
      "source": [
        "# creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(lines, window=10)\n",
        "\n",
        "glove = Glove(no_components=30, learning_rate=0.05)\n",
        " \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('/content/glove2582020.model')\n",
        "\n",
        "# print(glove.word_vectors[glove.dictionary['tweet']])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adSLVqTbhGQx"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "!unzip glove*.zip\n",
        "\n",
        "!ls\n",
        "#!p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC2QZno2hjly"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embeddings_index['rushi']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBnfYFyIj5Gh"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pQbUwjJkE7p"
      },
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcshdD3RkJyR"
      },
      "source": [
        "glove_file = datapath('/content/glove.6B.100d.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
        "\n",
        "model.most_similar('obama')\n",
        "\n",
        "model.most_similar('banana')\n",
        "\n",
        "model.most_similar(negative='banana')\n",
        "\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X099StxokLj-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}