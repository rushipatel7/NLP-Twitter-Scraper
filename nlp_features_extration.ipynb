{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCAfUpFOJJ9W"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sky Sports Cricket</td>\n",
       "      <td>2020-07-08 10:24:04</td>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sky Sports Cricket</td>\n",
       "      <td>2020-07-08 10:37:21</td>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sky Sports Cricket</td>\n",
       "      <td>2020-07-08 10:08:16</td>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCBS 106.9 FM/740 AM</td>\n",
       "      <td>2020-07-07 22:41:40</td>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cincinnati Reds</td>\n",
       "      <td>2020-07-07 20:06:40</td>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                 time  \\\n",
       "0    Sky Sports Cricket  2020-07-08 10:24:04   \n",
       "1    Sky Sports Cricket  2020-07-08 10:37:21   \n",
       "2    Sky Sports Cricket  2020-07-08 10:08:16   \n",
       "3  KCBS 106.9 FM/740 AM  2020-07-07 22:41:40   \n",
       "4       Cincinnati Reds  2020-07-07 20:06:40   \n",
       "\n",
       "                                               tweet  \n",
       "0  \"Until we educate the entire human race, this ...  \n",
       "1  \"We've all been looking away for too long.\" \\n...  \n",
       "2  \"If you don't educate people, they'll keep gro...  \n",
       "3  BREAKING: The #Martinez couple caught on video...  \n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tweet.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Until we educate the entire human race, this thing will not stop.\" \\n\\nMichael Holding delivers a powerful message, explaining why #BlackLivesMatter.',\n",
       " '\"We\\'ve all been looking away for too long.\" \\n\\n@nassercricket opens up on his experiences of racism, the impact of the killing of George Floyd and why people should be proud to wear #BlackLivesMatter badges.',\n",
       " '\"If you don\\'t educate people, they\\'ll keep growing up in that sort of society and you\\'ll not get meaningful change.\" \\n\\nMichael Holding and @ejrainfordbrent say that institutionalised racism must be eradicated for the good of humanity. #BlackLivesMatter',\n",
       " \"BREAKING: The #Martinez couple caught on video painting over the approved #BlackLivesMatter mural on #FourthofJuly are being charged with a hate crime, according to a release from the #ContraCostaCounty District Attorney's office.\",\n",
       " \"That's our first baseman. \\n\\n#BlackLivesMatter\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_list = data['tweet'].tolist()\n",
    "tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "R8_90iscJJ9a",
    "outputId": "7ce1b09d-a6cd-45f8-84b9-1e8aab4a9329",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"Until we educate the entire human race, this ...\n",
       "1    \"We've all been looking away for too long.\" \\n...\n",
       "2    \"If you don't educate people, they'll keep gro...\n",
       "3    BREAKING: The #Martinez couple caught on video...\n",
       "4      That's our first baseman. \\n\\n#BlackLivesMatter\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "1vtwdlSRJJ9f",
    "outputId": "048fa61a-21bc-4cfb-9c9b-2168e30189a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  word_count\n",
       "0  \"Until we educate the entire human race, this ...          21\n",
       "1  \"We've all been looking away for too long.\" \\n...          34\n",
       "2  \"If you don't educate people, they'll keep gro...          37\n",
       "3  BREAKING: The #Martinez couple caught on video...          32\n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter           5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Words\n",
    "data['word_count'] = data['tweet'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data[['tweet','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "8G550nSYJJ9k",
    "outputId": "d0afe8a1-15c7-4dd7-e720-c97fdbc94b59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  char_count\n",
       "0  \"Until we educate the entire human race, this ...         148\n",
       "1  \"We've all been looking away for too long.\" \\n...         206\n",
       "2  \"If you don't educate people, they'll keep gro...         252\n",
       "3  BREAKING: The #Martinez couple caught on video...         230\n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter          45"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of characters\n",
    "data['char_count'] = data['tweet'].str.len() ## this also includes spaces\n",
    "data[['tweet','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "4JhIVUkHJJ9o",
    "outputId": "2a81f765-5cae-4190-e581-1b9ee6175dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Until', 'we', 'educate', 'the', 'entire', 'human', 'race,', 'this', 'thing', 'will', 'not', 'stop.\"', 'Michael', 'Holding', 'delivers', 'a', 'powerful', 'message,', 'explaining', 'why']\n",
      "20\n",
      "108\n",
      "['\"We\\'ve', 'all', 'been', 'looking', 'away', 'for', 'too', 'long.\"', '@nassercricket', 'opens', 'up', 'on', 'his', 'experiences', 'of', 'racism,', 'the', 'impact', 'of', 'the', 'killing', 'of', 'George', 'Floyd', 'and', 'why', 'people', 'should', 'be', 'proud', 'to', 'wear', '#BlackLivesMatter']\n",
      "33\n",
      "164\n",
      "['\"If', 'you', \"don't\", 'educate', 'people,', \"they'll\", 'keep', 'growing', 'up', 'in', 'that', 'sort', 'of', 'society', 'and', \"you'll\", 'not', 'get', 'meaningful', 'change.\"', 'Michael', 'Holding', 'and', '@ejrainfordbrent', 'say', 'that', 'institutionalised', 'racism', 'must', 'be', 'eradicated', 'for', 'the', 'good', 'of', 'humanity.']\n",
      "36\n",
      "197\n",
      "['BREAKING:', 'The', '#Martinez', 'couple', 'caught', 'on', 'video', 'painting', 'over', 'the', 'approved', '#BlackLivesMatter', 'mural', 'on', '#FourthofJuly', 'are', 'being', 'charged', 'with', 'a', 'hate', 'crime,', 'according', 'to', 'a', 'release', 'from', 'the', '#ContraCostaCounty', 'District', \"Attorney's\"]\n",
      "31\n",
      "192\n",
      "[\"That's\", 'our', 'first', 'baseman.']\n",
      "4\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>4.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>5.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>6.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  avg_word\n",
       "0  \"Until we educate the entire human race, this ...  5.400000\n",
       "1  \"We've all been looking away for too long.\" \\n...  4.969697\n",
       "2  \"If you don't educate people, they'll keep gro...  5.472222\n",
       "3  BREAKING: The #Martinez couple caught on video...  6.193548\n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter  5.500000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average Word Length\n",
    "#Number of characters(without space count)/Total number of words\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()[:-1]\n",
    "  print(words)\n",
    "  print(len(words))\n",
    "  print(sum(len(word) for word in words))\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['tweet'].apply(lambda x: avg_word(x))\n",
    "data[['tweet','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "-rR3hQmpJJ9r",
    "outputId": "e27740ba-d66d-4091-e0e1-aac1c8d4a591"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  stopwords\n",
       "0  \"Until we educate the entire human race, this ...          7\n",
       "1  \"We've all been looking away for too long.\" \\n...         17\n",
       "2  \"If you don't educate people, they'll keep gro...         15\n",
       "3  BREAKING: The #Martinez couple caught on video...         12\n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter          1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['stopwords'] = data['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data[['tweet','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "kkiz2drXJJ9v",
    "outputId": "0243318b-5896-428b-dcc5-78edf984191b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  hastags\n",
       "0  \"Until we educate the entire human race, this ...        1\n",
       "1  \"We've all been looking away for too long.\" \\n...        1\n",
       "2  \"If you don't educate people, they'll keep gro...        1\n",
       "3  BREAKING: The #Martinez couple caught on video...        4\n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter        1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of special characters\n",
    "data['hastags'] = data['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "data[['tweet','hastags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mTaSFcxBJJ90",
    "outputId": "803cb36c-3597-4046-a59f-c594f1aeff50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  numerics\n",
       "0  \"Until we educate the entire human race, this ...         0\n",
       "1  \"We've all been looking away for too long.\" \\n...         0\n",
       "2  \"If you don't educate people, they'll keep gro...         0\n",
       "3  BREAKING: The #Martinez couple caught on video...         0\n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter         0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of numerics\n",
    "data['numerics'] = data['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "data[['tweet','numerics']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4jyNUNeTJJ94",
    "outputId": "c88a0927-70d7-4c41-937f-4078fb2f30dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  upper\n",
       "0  \"Until we educate the entire human race, this ...      0\n",
       "1  \"We've all been looking away for too long.\" \\n...      0\n",
       "2  \"If you don't educate people, they'll keep gro...      0\n",
       "3  BREAKING: The #Martinez couple caught on video...      1\n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter      0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Uppercase words\n",
    "data['upper'] = data['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "data[['tweet','upper']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "H3YKm8lgJJ97",
    "outputId": "cc406a3b-d940-4ed4-89e3-99086cedd5d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN ('race', 'NN')\n",
      "NN ('thing', 'NN')\n",
      "NNP ('Michael', 'NNP')\n",
      "NNP ('Holding', 'NNP')\n",
      "NN ('message', 'NN')\n",
      "NNP ('BlackLivesMatter', 'NNP')\n",
      "NN ('@', 'NN')\n",
      "NN ('nassercricket', 'NN')\n",
      "NNS ('experiences', 'NNS')\n",
      "NN ('racism', 'NN')\n",
      "NN ('impact', 'NN')\n",
      "NN ('killing', 'NN')\n",
      "NNP ('George', 'NNP')\n",
      "NNP ('Floyd', 'NNP')\n",
      "NNS ('people', 'NNS')\n",
      "NNP ('BlackLivesMatter', 'NNP')\n",
      "NNS ('badges', 'NNS')\n",
      "NNS ('people', 'NNS')\n",
      "NN ('sort', 'NN')\n",
      "NN ('society', 'NN')\n",
      "NN ('change', 'NN')\n",
      "NNP ('Michael', 'NNP')\n",
      "NNP ('Holding', 'NNP')\n",
      "NN ('ejrainfordbrent', 'NN')\n",
      "NN ('racism', 'NN')\n",
      "NN ('humanity', 'NN')\n",
      "NNP ('BlackLivesMatter', 'NNP')\n",
      "NN ('BREAKING', 'NN')\n",
      "NNP ('Martinez', 'NNP')\n",
      "NN ('couple', 'NN')\n",
      "NN ('caught', 'NN')\n",
      "NN ('video', 'NN')\n",
      "NN ('painting', 'NN')\n",
      "NNP ('BlackLivesMatter', 'NNP')\n",
      "NN ('mural', 'NN')\n",
      "NNP ('FourthofJuly', 'NNP')\n",
      "NN ('hate', 'NN')\n",
      "NN ('crime', 'NN')\n",
      "NN ('release', 'NN')\n",
      "NNP ('ContraCostaCounty', 'NNP')\n",
      "NNP ('District', 'NNP')\n",
      "NNP ('Attorney', 'NNP')\n",
      "NN ('office', 'NN')\n",
      "NN ('baseman', 'NN')\n",
      "NNP ('BlackLivesMatter', 'NNP')\n",
      "VBP ('educate', 'VBP')\n",
      "VB ('stop', 'VB')\n",
      "VBZ ('delivers', 'VBZ')\n",
      "VBG ('explaining', 'VBG')\n",
      "VBP (\"'ve\", 'VBP')\n",
      "VBN ('been', 'VBN')\n",
      "VBG ('looking', 'VBG')\n",
      "VBZ ('opens', 'VBZ')\n",
      "VB ('be', 'VB')\n",
      "VB ('wear', 'VB')\n",
      "VBP ('do', 'VBP')\n",
      "VB ('educate', 'VB')\n",
      "VB ('keep', 'VB')\n",
      "VBG ('growing', 'VBG')\n",
      "VB ('get', 'VB')\n",
      "VBP ('say', 'VBP')\n",
      "VB ('be', 'VB')\n",
      "VBN ('eradicated', 'VBN')\n",
      "VBP ('are', 'VBP')\n",
      "VBG ('being', 'VBG')\n",
      "VBN ('charged', 'VBN')\n",
      "VBG ('according', 'VBG')\n",
      "VBZ (\"'s\", 'VBZ')\n",
      "JJ ('entire', 'JJ')\n",
      "JJ ('human', 'JJ')\n",
      "JJ ('powerful', 'JJ')\n",
      "JJ ('long', 'JJ')\n",
      "JJ ('proud', 'JJ')\n",
      "JJ ('meaningful', 'JJ')\n",
      "JJ ('@', 'JJ')\n",
      "JJ ('institutionalised', 'JJ')\n",
      "JJ ('good', 'JJ')\n",
      "JJ ('approved', 'JJ')\n",
      "JJ ('first', 'JJ')\n",
      "RB ('not', 'RB')\n",
      "WRB ('why', 'WRB')\n",
      "RB ('away', 'RB')\n",
      "RB ('too', 'RB')\n",
      "WRB ('why', 'WRB')\n",
      "RB (\"n't\", 'RB')\n",
      "RB ('not', 'RB')\n",
      "PRP ('we', 'PRP')\n",
      "PRP ('We', 'PRP')\n",
      "PRP$ ('his', 'PRP$')\n",
      "PRP ('you', 'PRP')\n",
      "PRP ('they', 'PRP')\n",
      "PRP ('you', 'PRP')\n",
      "PRP$ ('our', 'PRP$')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  noun_count  verb_count  \\\n",
       "0  \"Until we educate the entire human race, this ...           6           4   \n",
       "1  \"We've all been looking away for too long.\" \\n...          11           6   \n",
       "2  \"If you don't educate people, they'll keep gro...          10           8   \n",
       "3  BREAKING: The #Martinez couple caught on video...          16           4   \n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter           2           1   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \n",
       "0          3          2           1  \n",
       "1          2          3           2  \n",
       "2          4          2           3  \n",
       "3          1          0           0  \n",
       "4          1          0           1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "from textblob import TextBlob, Word, Blobber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "                print(ppo, tup)\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "data['noun_count'] = data['tweet'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "data['verb_count'] = data['tweet'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "data['adj_count'] = data['tweet'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "data['adv_count'] = data['tweet'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "data['pron_count'] = data['tweet'].apply(lambda x: check_pos_tag(x, 'pron'))\n",
    "data[['tweet','noun_count','verb_count','adj_count', 'adv_count', 'pron_count' ]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "bLnQl2fFMLf3",
    "outputId": "0a240edf-1b2a-4139-e3de-a40c3b4eafa9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sky Sports Cricket</td>\n",
       "      <td>2020-07-08 10:24:04</td>\n",
       "      <td>\"Until we educate the entire human race, this ...</td>\n",
       "      <td>21</td>\n",
       "      <td>148</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sky Sports Cricket</td>\n",
       "      <td>2020-07-08 10:37:21</td>\n",
       "      <td>\"We've all been looking away for too long.\" \\n...</td>\n",
       "      <td>34</td>\n",
       "      <td>206</td>\n",
       "      <td>4.969697</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sky Sports Cricket</td>\n",
       "      <td>2020-07-08 10:08:16</td>\n",
       "      <td>\"If you don't educate people, they'll keep gro...</td>\n",
       "      <td>37</td>\n",
       "      <td>252</td>\n",
       "      <td>5.472222</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCBS 106.9 FM/740 AM</td>\n",
       "      <td>2020-07-07 22:41:40</td>\n",
       "      <td>BREAKING: The #Martinez couple caught on video...</td>\n",
       "      <td>32</td>\n",
       "      <td>230</td>\n",
       "      <td>6.193548</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cincinnati Reds</td>\n",
       "      <td>2020-07-07 20:06:40</td>\n",
       "      <td>That's our first baseman. \\n\\n#BlackLivesMatter</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                 time  \\\n",
       "0    Sky Sports Cricket  2020-07-08 10:24:04   \n",
       "1    Sky Sports Cricket  2020-07-08 10:37:21   \n",
       "2    Sky Sports Cricket  2020-07-08 10:08:16   \n",
       "3  KCBS 106.9 FM/740 AM  2020-07-07 22:41:40   \n",
       "4       Cincinnati Reds  2020-07-07 20:06:40   \n",
       "\n",
       "                                               tweet  word_count  char_count  \\\n",
       "0  \"Until we educate the entire human race, this ...          21         148   \n",
       "1  \"We've all been looking away for too long.\" \\n...          34         206   \n",
       "2  \"If you don't educate people, they'll keep gro...          37         252   \n",
       "3  BREAKING: The #Martinez couple caught on video...          32         230   \n",
       "4    That's our first baseman. \\n\\n#BlackLivesMatter           5          45   \n",
       "\n",
       "   avg_word  stopwords  hastags  numerics  upper  noun_count  verb_count  \\\n",
       "0  5.400000          7        1         0      0           6           4   \n",
       "1  4.969697         17        1         0      0          11           6   \n",
       "2  5.472222         15        1         0      0          10           8   \n",
       "3  6.193548         12        4         0      1          16           4   \n",
       "4  5.500000          1        1         0      0           2           1   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \n",
       "0          3          2           1  \n",
       "1          2          3           2  \n",
       "2          4          2           3  \n",
       "3          1          0           0  \n",
       "4          1          0           1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HnWMnS3axCty"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "h2mCGblw3axa",
    "outputId": "f03ddd2d-9a69-4449-ffc2-ce89a605ebf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0\n",
      "  0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0]\n",
      " [0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0\n",
      "  0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 3 0 1 1 0 0 0 1 0 1 0 1\n",
      "  0 0 1 0 0 0 0 2 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1\n",
      "  1 1 0 0 1 0 1 1 0 1 1 1 0 2 0 0 0 1 0 1 0 1 0 1 2 0 0 0 0 0 0 1 0 0 0 1\n",
      "  0 1 0 1 1 0 2 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 2]\n",
      " [1 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 2 0 0 1 1 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 3 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "A_vec = cv.fit_transform(tweet_list)\n",
    "print(A_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "uCwXOS8A3tNZ",
    "outputId": "3b02a161-972f-4dca-c653-88314b19a666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29296785 0.         0.         0.29296785\n",
      "  0.         0.         0.29296785 0.         0.         0.29296785\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29296785 0.         0.29296785 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.29296785 0.23636462 0.         0.         0.\n",
      "  0.         0.         0.         0.29296785 0.         0.29296785\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29296785 0.29296785 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.25       0.         0.25\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25       0.\n",
      "  0.25       0.         0.25       0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25       0.\n",
      "  0.25       0.         0.         0.25       0.25       0.\n",
      "  0.         0.         0.         0.         0.25       0.25\n",
      "  0.         0.         0.25       0.         0.25       0.\n",
      "  0.         0.25       0.         0.         0.         0.\n",
      "  0.         0.         0.25       0.         0.25      ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23155274 0.         0.\n",
      "  0.         0.         0.         0.         0.23155274 0.\n",
      "  0.23155274 0.23155274 0.         0.23155274 0.         0.\n",
      "  0.         0.         0.         0.23155274 0.23155274 0.\n",
      "  0.         0.23155274 0.         0.23155274 0.         0.23155274\n",
      "  0.         0.23155274 0.23155274 0.         0.         0.\n",
      "  0.23155274 0.         0.18681529 0.         0.         0.\n",
      "  0.         0.23155274 0.         0.         0.         0.\n",
      "  0.23155274 0.         0.         0.23155274 0.23155274 0.23155274\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.23570226 0.23570226 0.23570226 0.         0.         0.\n",
      "  0.23570226 0.23570226 0.23570226 0.         0.23570226 0.23570226\n",
      "  0.23570226 0.23570226 0.         0.23570226 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23570226 0.         0.         0.         0.23570226\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.23570226\n",
      "  0.         0.         0.         0.23570226 0.         0.\n",
      "  0.23570226 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.23570226 0.         0.         0.\n",
      "  0.         0.         0.         0.23570226 0.        ]\n",
      " [0.         0.         0.         0.         1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tv=TfidfVectorizer(ngram_range = (2,2),stop_words = 'english', token_pattern=r'[a-z]+[a-z]')\n",
    "t_vec = tv.fit_transform(tweet_list)\n",
    "print(t_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FwbtTugkbPPa"
   },
   "outputs": [],
   "source": [
    "feature_names = tv.get_feature_names()\n",
    "\n",
    "dense = t_vec.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "lMDZ7y8Xi-SK",
    "outputId": "f5bb449c-fce9-443a-cdad-9d4c30f5d8a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['according release',\n",
       " 'approved blacklivesmatter',\n",
       " 'attorney office',\n",
       " 'away long',\n",
       " 'baseman blacklivesmatter',\n",
       " 'blacklivesmatter badges',\n",
       " 'blacklivesmatter mural',\n",
       " 'breaking martinez',\n",
       " 'caught video',\n",
       " 'change michael',\n",
       " 'charged hate',\n",
       " 'contracostacounty district',\n",
       " 'couple caught',\n",
       " 'crime according',\n",
       " 'delivers powerful',\n",
       " 'district attorney',\n",
       " 'don educate',\n",
       " 'educate entire',\n",
       " 'educate people',\n",
       " 'ejrainfordbrent say',\n",
       " 'entire human',\n",
       " 'eradicated good',\n",
       " 'experiences racism',\n",
       " 'explaining blacklivesmatter',\n",
       " 'floyd people',\n",
       " 'fourthofjuly charged',\n",
       " 'george floyd',\n",
       " 'good humanity',\n",
       " 'growing sort',\n",
       " 'hate crime',\n",
       " 'holding delivers',\n",
       " 'holding ejrainfordbrent',\n",
       " 'human race',\n",
       " 'humanity blacklivesmatter',\n",
       " 'impact killing',\n",
       " 'institutionalised racism',\n",
       " 'killing george',\n",
       " 'll growing',\n",
       " 'll meaningful',\n",
       " 'long nassercricket',\n",
       " 'looking away',\n",
       " 'martinez couple',\n",
       " 'meaningful change',\n",
       " 'message explaining',\n",
       " 'michael holding',\n",
       " 'mural fourthofjuly',\n",
       " 'nassercricket opens',\n",
       " 'opens experiences',\n",
       " 'painting approved',\n",
       " 'people ll',\n",
       " 'people proud',\n",
       " 'powerful message',\n",
       " 'proud wear',\n",
       " 'race thing',\n",
       " 'racism eradicated',\n",
       " 'racism impact',\n",
       " 'release contracostacounty',\n",
       " 'say institutionalised',\n",
       " 'society ll',\n",
       " 'sort society',\n",
       " 'stop michael',\n",
       " 'thing stop',\n",
       " 've looking',\n",
       " 'video painting',\n",
       " 'wear blacklivesmatter']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "MyzOm5ROk_YL",
    "outputId": "cb3d4f0b-7195-4861-9941-2f6f151007f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>according release</th>\n",
       "      <th>approved blacklivesmatter</th>\n",
       "      <th>attorney office</th>\n",
       "      <th>away long</th>\n",
       "      <th>baseman blacklivesmatter</th>\n",
       "      <th>blacklivesmatter badges</th>\n",
       "      <th>blacklivesmatter mural</th>\n",
       "      <th>breaking martinez</th>\n",
       "      <th>caught video</th>\n",
       "      <th>change michael</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.969697</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231553</td>\n",
       "      <td>...</td>\n",
       "      <td>5.472222</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.193548</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   according release  approved blacklivesmatter  attorney office  away long  \\\n",
       "0           0.000000                   0.000000         0.000000       0.00   \n",
       "1           0.000000                   0.000000         0.000000       0.25   \n",
       "2           0.000000                   0.000000         0.000000       0.00   \n",
       "3           0.235702                   0.235702         0.235702       0.00   \n",
       "4           0.000000                   0.000000         0.000000       0.00   \n",
       "\n",
       "   baseman blacklivesmatter  blacklivesmatter badges  blacklivesmatter mural  \\\n",
       "0                       0.0                     0.00                0.000000   \n",
       "1                       0.0                     0.25                0.000000   \n",
       "2                       0.0                     0.00                0.000000   \n",
       "3                       0.0                     0.00                0.235702   \n",
       "4                       1.0                     0.00                0.000000   \n",
       "\n",
       "   breaking martinez  caught video  change michael  ...  avg_word  stopwords  \\\n",
       "0           0.000000      0.000000        0.000000  ...  5.400000          7   \n",
       "1           0.000000      0.000000        0.000000  ...  4.969697         17   \n",
       "2           0.000000      0.000000        0.231553  ...  5.472222         15   \n",
       "3           0.235702      0.235702        0.000000  ...  6.193548         12   \n",
       "4           0.000000      0.000000        0.000000  ...  5.500000          1   \n",
       "\n",
       "   hastags  numerics  upper  noun_count  verb_count  adj_count  adv_count  \\\n",
       "0        1         0      0           6           4          3          2   \n",
       "1        1         0      0          11           6          2          3   \n",
       "2        1         0      0          10           8          4          2   \n",
       "3        4         0      1          16           4          1          0   \n",
       "4        1         0      0           2           1          1          0   \n",
       "\n",
       "   pron_count  \n",
       "0           1  \n",
       "1           2  \n",
       "2           3  \n",
       "3           0  \n",
       "4           1  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c =pd.concat([df,data], axis=1)\n",
    "df_c.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_features_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
